# -*- coding: utf-8 -*-
"""Copy of Copy of Readability new data

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CDtR5Y-CCg9MJ4FJjMix06ixH0ajnibt
"""

! pip install --upgrade pandas

!pip install  textatistic
!pip install  textstat
from textatistic import Textatistic

import textstat
import csv
import pandas as pd
train = pd.read_csv('new_read.csv' , encoding = 'unicode_escape')

train_a=train['True statement'].apply(textstat.flesch_reading_ease)


train_b=train['True statement'].apply(textstat.smog_index)


train_c=train['True statement'].apply(textstat.flesch_kincaid_grade)


train_d=train['True statement'].apply(textstat.coleman_liau_index)



train_e=train['True statement'].apply(textstat.automated_readability_index)


train_f=train['True statement'].apply(textstat.dale_chall_readability_score)



train_g=train['True statement'].apply(textstat.difficult_words)


train_h=train['True statement'].apply(textstat.linsear_write_formula)


train_i=train['True statement'].apply(textstat.difficult_words)


train_j=train['True statement'].apply(textstat.gunning_fog)


train_k=train['True statement'].apply(textstat.text_standard)







frames = [train, 
          train_a,
          train_b,
          train_c,
          train_d, 
          train_e, 
          train_f,  
          train_g,
          train_h,
          train_i,
          train_j, 
          train_k ]
result = pd.concat(frames, axis=1)
result.columns = ['True statement',
                  'True_fleshes',
                  'True_smog_index',
                  'True_flesch_kincaid_grade',
                  'True_coleman_liau_index',
                  'True_automated_readability_index',
                  'True_dale_chall_readability_score',
                  'True_difficult_words',
                  'True_linsear_write_formula',
                  'True_difficult_words',
                  'True_gunning_fog',
                  'True_text_standard']
#train2.to_csv (r'dataframe_d.csv', index = False, header=True)
#train3.to_csv (r'dataframe_e.csv', index = False, header=True)
result.to_csv(r'ds.csv', index = False, header='false')
#print(textstat.flesch_reading_ease(train))

#for row in df.iterrows():
    #  x.dict()
   # print(row)
    #print(textstat.flesch_reading_ease(row))
    #s = Textatistic(x)
    #print(row[1])
    #s.flesch_score

import pandas as pd
df = pd.read_csv('correlation matrix.csv' , encoding = 'unicode_escape')

import numpy as np

# name of the label (can be seen in the dataframe)
label = 'C'



# list with feature names (V1, V2, V3, ...)
features = df.columns.tolist()
#features.remove(label)

from scipy.stats import pointbiserialr
from math import sqrt

def getMerit(subset):
    k = len(subset)

    # average feature-class correlation
    rcf_all = []
    for feature in subset:
        coeff = pointbiserialr( df[label], df[feature] )
        print(df[label], df[feature],coeff)
        rcf_all.append( abs( coeff.correlation ) )
    rcf = np.mean( rcf_all )
    print(rcf)

    # average feature-feature correlation
    corr = df[subset].corr()
    corr.values[np.tril_indices_from(corr.values)] = np.nan
    corr = abs(corr)
    rff = corr.unstack().mean()

    return (k * rcf) / sqrt(k + k * (k-1) * rff)

from scipy import stats
import numpy as np
corr_list = []
y = df['C'].astype(float)


for column in df:
    x=df[column]
    corr = stats.pointbiserialr(list(x), list(y))
    corr_list.append(corr[0])
print(corr_list)

!pip install dython

pip install scipy

import pandas as pd
from dython.nominal import associations

from dython.nominal import identify_nominal_columns
categorical_features=identify_nominal_columns(df)
categorical_features

associations(df, nominal_columns='auto', numerical_columns=None, mark_columns=False, nom_nom_assoc='cramer', num_num_assoc='pearson',  ax=None, figsize=None, annot=True, fmt='.2f', cmap=None, sv_color='silver', cbar=True, vmax=1.0, vmin=None, plot=True, compute_only=False, clustering= None, title=None, filename=None)

complete_correlation= associations(df, filename= 'complete_correlation.png', figsize=(20,20))